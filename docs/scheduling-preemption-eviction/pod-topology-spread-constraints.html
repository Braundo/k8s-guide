<!DOCTYPE html>

<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<link href="../../assets/logo.png" rel="icon" type="image/png"/>
<title>Pod Topology Spread Constraints</title>
<link href="../../styles.css" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@300;400;500;700&amp;display=swap" rel="stylesheet"/>
<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"/>
<link href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/themes/prism-dracula.min.css" rel="stylesheet"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/prism.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.8/clipboard.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.23.0/components/prism-yaml.min.js"></script>
</link></head>
<body class="dark-mode" onload="loadSidebar()">
<!--Header -->
<header>
<div class="header-content">
<div class="title-and-subheader">
<div class="title-container">
<a href="/index.html">
<img alt="Logo" id="logo" src="../../assets/logo.png"/>
</a>
<h1>K8s Guide</h1><br/><br/><br/>
</div>
<h3 class="sub-header">Your TLDR guide to Kubernetes documentation</h3>
</div>
</div></header>
<div id="hamburger-container">
<button id="hamburger-menu">â˜°</button>
</div>
<!--Sidebar -->
<nav id="sidebar"></nav>
<!--Main Content -->
<main>
<h1>Pod Topology Spread Constraints</h1><br/><br/><br/>
<h3>Motivation</h3>

The primary motivation is to distribute Pods in a way that they are not all scheduled on the same node or same zone, which could be a single point of failure. For example, if you have a service that scales its Pods automatically, you don't want all Pods to be on the same node. As you scale up, you might also want to consider network latency and costs, aiming to distribute Pods across different data centers or zones.

<br/><br/><br/>
<h3>topologySpreadConstraints Field</h3>

This is the field you add to your Pod spec to define the constraints. It has several sub-fields:

<li>`maxSkew`: Defines how unevenly Pods may be distributed. A lower number means a more even distribution.</li>
<li>`topologyKey`: The key for node labels to define a topology (e.g., `zone`, `node`, etc.)</li>
<li>`whenUnsatisfiable`: What to do if the constraint can't be satisfied (`DoNotSchedule` or `ScheduleAnyway`).</li>
<li>`labelSelector`: Used to find Pods that these constraints apply to.</li>
<li>`minDomains`: (Optional) Minimum number of domains (like zones or nodes) that must be eligible for Pod placement.</li>
<br/><br/><br/>
<h3>Node Labels</h3>

Nodes should be labeled with the topology keys you intend to use, like `zone` or `region`. These labels are used by the scheduler to make decisions.

<br/><br/><br/>
<h3>Multiple Constraints</h3>

You can define multiple `topologySpreadConstraints`. In such cases, all constraints must be satisfied for a Pod to be scheduled.

<br/><br/><br/>
<h3>Interaction with Node Affinity</h3>

If a Pod also has node affinity rules, then the scheduler will consider those rules in conjunction with the topology spread constraints.

<br/><br/><br/>
<h3>Example 1: Basic Spread Constraints</h3>
This example ensures that the Pods are spread across different zones.
<div class="code-block">
<button class="copy-button" data-clipboard-target=".code">
<span class="material-icons">content_copy</span>
</button>
<pre><code class="code language-yaml">
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: myapp
  containers:
  - name: nginx
    image: nginx
  </code></pre>
</div>
<br/><br/><br/>
<h3>Example 2: Multiple Constraints</h3>

This example ensures that the Pods are spread both across zones and nodes.
<div class="code-block">
<button class="copy-button" data-clipboard-target=".code">
<span class="material-icons">content_copy</span>
</button>
<pre><code class="code language-yaml">
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: myapp
  - maxSkew: 2
    topologyKey: node
    whenUnsatisfiable: ScheduleAnyway
    labelSelector:
      matchLabels:
        app: myapp
  containers:
  - name: nginx
    image: nginx
  </code></pre>
</div>
<br/><br/><br/>
<h3>Example 3: Using minDomains</h3>

This example ensures that Pods are spread across at least 2 zones.
<div class="code-block">
<button class="copy-button" data-clipboard-target=".code">
<span class="material-icons">content_copy</span>
</button>
<pre><code class="code language-yaml">
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: myapp
    minDomains: 2
  containers:
  - name: nginx
    image: nginx
  </code></pre>
</div>
<br/><br/><br/>
<h3>Example 4: Interaction with Node Affinity</h3>

This example shows how node affinity can be combined with spread constraints.
<div class="code-block">
<button class="copy-button" data-clipboard-target=".code">
<span class="material-icons">content_copy</span>
</button>
<pre><code class="code language-yaml">
apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  affinity:
    nodeAffinity:
      requiredDuringScheduling \
      IgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: hardware
            operator: In
            values:
            - fast-ssd
  topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: zone
    whenUnsatisfiable: DoNotSchedule
    labelSelector:
      matchLabels:
        app: myapp
  containers:
  - name: nginx
    image: nginx
  </code></pre>
</div>
<br/><br/>
<h3>Implicit Conventions</h3>
<li>Only Pods in the same namespace as the incoming Pod are considered as matching candidates.</li>
<li>Also, any nodes that don't have the `topologyKey` specified in `topologySpreadConstraints` are bypassed.</li>
<li>This feature is particularly useful for large, distributed, and dynamic clusters where you want to control the Pod distribution for reasons like high availability, data locality, and load balancing.</li>
<br/><br/><br/></main>
<link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet"/>
<!--Dark/Light Mode Toggle -->
<button id="mode-toggle" onclick="toggleMode()">
<span class="material-icons">brightness_7</span>
</button>
<!--Scroll-to-Top Button -->
<button id="scroll-top" onclick="scrollToTop()">
<span class="material-icons">arrow_upward</span>
</button>
<!-- Next Page Button -->
<button id="next-page" onclick="navigateNext()">
<span class="material-icons">arrow_forward</span>
</button>
<!-- Random Page Button -->
<button id="randomizer">
<span class="material-icons">shuffle</span>
</button>
<!--Mobile Menu -->
<div id="mobile-menu"></div>
<script src="../../script.js"></script>
</body>
</html>
